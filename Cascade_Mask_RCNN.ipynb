{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Et0RKkRAiHw",
        "outputId": "acbdc18a-01d2-43cf-8e5a-5c85cc84d926"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "Li8o44-s_cYe",
        "outputId": "ea7817ae-6c3f-4f5e-bf26-e5c4c79964bd"
      },
      "outputs": [],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "Fi8HI44q_cYf",
        "outputId": "3148320a-e711-4be4-b723-ba115d4763df"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkA41JuN_cYg"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKx29eh5_cYg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def is_coco_format(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Check if the main keys are present\n",
        "        if not all(key in data for key in [\"images\", \"annotations\", \"categories\"]):\n",
        "            return False\n",
        "\n",
        "        # Check if 'images' has the required keys\n",
        "        for image in data[\"images\"]:\n",
        "            if not all(key in image for key in [\"height\", \"width\", \"id\", \"file_name\"]):\n",
        "                return False\n",
        "\n",
        "        # Check if 'annotations' has the required keys\n",
        "        for annotation in data[\"annotations\"]:\n",
        "            if not all(key in annotation for key in [\"iscrowd\", \"image_id\", \"bbox\", \"category_id\", \"id\", \"area\"]):\n",
        "                return False\n",
        "\n",
        "        # Check if 'categories' has the required keys\n",
        "        for category in data[\"categories\"]:\n",
        "            if not all(key in category for key in [\"id\", \"name\"]):\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj-oZxwk_cYh"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/CarDD_release/CarDD_COCO/annotations/instances_train2017.json'\n",
        "result = is_coco_format(file_path)\n",
        "print(f\"Is COCO Format: {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0FglUfi_cYi"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_dataset_train\", {}, \"/content/drive/MyDrive/CarDD_release/CarDD_COCO/annotations/instances_train2017.json\", \"/content/drive/MyDrive/CarDD_release/CarDD_COCO/train2017\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbCfWyF3_cYi"
      },
      "outputs": [],
      "source": [
        "register_coco_instances(\"my_dataset_val\", {}, \"/content/drive/MyDrive/CarDD_release/CarDD_COCO/annotations/instances_val2017.json\", \"/content/drive/MyDrive/CarDD_release/CarDD_COCO/val2017\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOGhIMof_cYi",
        "outputId": "322c1346-33c4-41f4-d486-50bebb9ebfee"
      },
      "outputs": [],
      "source": [
        "from detectron2.data import DatasetCatalog\n",
        "\n",
        "def is_dataset_registered(name):\n",
        "    return name in DatasetCatalog.list()\n",
        "\n",
        "dataset_name = \"my_dataset_train\"\n",
        "if is_dataset_registered(dataset_name):\n",
        "    print(f\"The dataset '{dataset_name}' is registered.\")\n",
        "else:\n",
        "    print(f\"The dataset '{dataset_name}' is not registered.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "z0WTtYB1_cYj",
        "outputId": "8fdb2aaa-a10f-4a39-98af-ea3d990d54c7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset and retrieve metadata\n",
        "dataset_dicts = DatasetCatalog.get(dataset_name)\n",
        "dataset_metadata = MetadataCatalog.get(dataset_name)\n",
        "\n",
        "# Pick a random sample from the dataset\n",
        "sample = random.choice(dataset_dicts)\n",
        "\n",
        "# Read the image\n",
        "img = cv2.imread(sample[\"file_name\"])\n",
        "\n",
        "# Create a Visualizer object\n",
        "visualizer = Visualizer(img[:, :, ::-1], metadata=dataset_metadata)\n",
        "\n",
        "# Visualize the annotations\n",
        "vis_output = visualizer.draw_dataset_dict(sample)\n",
        "\n",
        "# Display the image using Matplotlib\n",
        "plt.imshow(vis_output.get_image()[:, :, ::-1])\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOAlpSZi_cYk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSqFdTSx_cYl"
      },
      "outputs": [],
      "source": [
        "from detectron2.data import DatasetMapper, build_detection_train_loader\n",
        "from detectron2.data import transforms as T\n",
        "import copy\n",
        "import torch\n",
        "from detectron2.data import detection_utils as utils\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvrsc3If_cYm"
      },
      "outputs": [],
      "source": [
        "def custom_mapper(dataset_dict):\n",
        "    dataset_dict = copy.deepcopy(dataset_dict)\n",
        "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
        "\n",
        "    transform_list = [\n",
        "        T.RandomRotation(angle=[90, 180, 270]),  # Simple rotation\n",
        "        T.RandomContrast(0.8, 1.2),             # Random contrast\n",
        "        T.RandomBrightness(0.8, 1.2),           # Random brightness\n",
        "    ]\n",
        "\n",
        "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
        "\n",
        "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
        "\n",
        "    annos = [\n",
        "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
        "        for obj in dataset_dict.pop(\"annotations\")\n",
        "    ]\n",
        "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
        "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
        "    return dataset_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoWeYIfk_cYm"
      },
      "outputs": [],
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-reIGQSJI1Bx",
        "outputId": "7dd2488b-126b-4bec-b509-42dfa2575f10"
      },
      "outputs": [],
      "source": [
        "def get_category_ids(dataset_dict_list):\n",
        "    category_ids = set()\n",
        "    for dataset_dict in dataset_dict_list:\n",
        "        for anno in dataset_dict['annotations']:\n",
        "            category_ids.add(anno['category_id'])\n",
        "    return category_ids\n",
        "\n",
        "dataset_dict_list = DatasetCatalog.get(\"my_dataset_train\")\n",
        "actual_category_ids = get_category_ids(dataset_dict_list)\n",
        "\n",
        "print(\"Actual Category IDs in the dataset:\", actual_category_ids)\n",
        "\n",
        "# Update your class_labels based on the actual category IDs\n",
        "class_labels = sorted(list(actual_category_ids))\n",
        "print(\"Updated Class Labels:\", class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSxUFPatE0Yk"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.sampler import Sampler\n",
        "import numpy as np\n",
        "\n",
        "class BalancedClassSampler(Sampler):\n",
        "    \"\"\"\n",
        "    Sampler that oversamples minority classes in the dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset_dict_list, class_labels):\n",
        "        self.dataset_dict_list = dataset_dict_list\n",
        "        self.indices = list(range(len(self.dataset_dict_list)))\n",
        "        self.num_samples = len(self.dataset_dict_list)\n",
        "        self.class_counts = self._count_classes(self.dataset_dict_list, class_labels)\n",
        "        self.weights = self._compute_weights()\n",
        "\n",
        "    def _count_classes(self, dataset_dict_list, class_labels):\n",
        "        count_dict = {label: 0 for label in class_labels}\n",
        "        for dataset_dict in dataset_dict_list:\n",
        "            for anno in dataset_dict['annotations']:\n",
        "                count_dict[anno['category_id']] += 1\n",
        "        return count_dict\n",
        "\n",
        "    def _compute_weights(self):\n",
        "        # Find the maximum class count to inverse the frequency\n",
        "        max_count = max(self.class_counts.values())\n",
        "        weights = []\n",
        "        for dataset_dict in self.dataset_dict_list:\n",
        "            # Find the minimum class count in this image\n",
        "            min_class_count = min(self.class_counts[anno['category_id']] for anno in dataset_dict['annotations'])\n",
        "            # The weight is higher if the image contains a minority class\n",
        "            weights.append(max_count / min_class_count)\n",
        "        return torch.tensor(weights, dtype=torch.float)\n",
        "\n",
        "    def __iter__(self):\n",
        "        # No need to iterate through self.indices as torch.multinomial will return indices directly\n",
        "        return iter(torch.multinomial(self.weights, self.num_samples, replacement=True).tolist())\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBueXW6vGm1H"
      },
      "outputs": [],
      "source": [
        "def custom_train_loader(cfg, dataset_name, class_labels):\n",
        "    # Fetch the dataset dictionary list from Detectron2's dataset registry\n",
        "    dataset_dicts = DatasetCatalog.get(dataset_name)\n",
        "\n",
        "    # Create a sampler instance\n",
        "    sampler = BalancedClassSampler(dataset_dicts, class_labels)\n",
        "\n",
        "    # Return the Detectron2 train loader with our custom sampler\n",
        "    return build_detection_train_loader(cfg, mapper=custom_mapper, sampler=sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UURRHextGoZ0"
      },
      "outputs": [],
      "source": [
        "class_labels = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "class CustomTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        # Use the name of your training dataset\n",
        "        return custom_train_loader(cfg, \"my_dataset_train\", class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBZ7EgaMHz7z"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def count_class_instances(dataset_dict_list, class_labels):\n",
        "    count_dict = {label: 0 for label in class_labels}\n",
        "    for dataset_dict in dataset_dict_list:\n",
        "        for anno in dataset_dict['annotations']:\n",
        "            count_dict[anno['category_id']] += 1\n",
        "    return count_dict\n",
        "\n",
        "def simulate_balanced_sampling(dataset_dict_list, class_labels, num_batches, batch_size):\n",
        "    sampler = BalancedClassSampler(dataset_dict_list, class_labels)\n",
        "    # Assuming you want to simulate the same number of samples as your training set\n",
        "    num_samples = num_batches * batch_size\n",
        "    sampled_indices = [next(iter(sampler)) for _ in range(num_samples)]\n",
        "    sampled_count_dict = {label: 0 for label in class_labels}\n",
        "    for idx in sampled_indices:\n",
        "        for anno in dataset_dict_list[idx]['annotations']:\n",
        "            sampled_count_dict[anno['category_id']] += 1\n",
        "    return sampled_count_dict\n",
        "\n",
        "def plot_class_distribution(counts, title):\n",
        "    labels = list(counts.keys())\n",
        "    values = list(counts.values())\n",
        "\n",
        "    plt.bar(labels, values)\n",
        "    plt.xlabel('Class ID')\n",
        "    plt.ylabel('Number of Instances')\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi0FpMTzIDOo",
        "outputId": "20fa2e04-e039-4e9e-df7c-e06bdb5d13d7"
      },
      "outputs": [],
      "source": [
        "dataset_dict_list = DatasetCatalog.get(\"my_dataset_train\")\n",
        "original_counts = count_class_instances(dataset_dict_list, class_labels)\n",
        "sampled_counts = simulate_balanced_sampling(dataset_dict_list, class_labels, len(dataset_dict_list),4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "TwtlmSV8IFb-",
        "outputId": "69f4b06f-befc-4bca-c170-294e86d0bf5b"
      },
      "outputs": [],
      "source": [
        "plot_class_distribution(original_counts, 'Original Class Distribution')\n",
        "plot_class_distribution(sampled_counts, 'Class Distribution After Sampling')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w70vTeWc_cYn",
        "outputId": "c436bf22-8837-4dc8-f857-afd451755dc9"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters\n",
        "batch_size = 8 \n",
        "\n",
        "# Configure the model\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = batch_size\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # Starting learning rate\n",
        "cfg.TEST.EVAL_PERIOD = 1000\n",
        "cfg.SOLVER.MAX_ITER = 5000\n",
        "cfg.SOLVER.STEPS = (2000, 3000)  # Points to decrease the learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
        "# Learning rate scheduler configuration\n",
        "cfg.SOLVER.WARMUP_ITERS = 1000\n",
        "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
        "cfg.SOLVER.GAMMA = 0.1  # Learning rate reduction factor\n",
        "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
        "cfg.SOLVER.WEIGHT_DECAY = 0.001  # Regularization - weight decay\n",
        "\n",
        "# Set up output directory\n",
        "output_dir = \"/content/drive/MyDrive/output_cascade\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "cfg.OUTPUT_DIR = output_dir\n",
        "\n",
        "# Initialize the trainer and start training\n",
        "trainer = CustomTrainer(cfg)\n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "d2rC35yX0bFJ",
        "outputId": "12c1d203-d60c-4881-fa2d-fb2464f60db4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to your JSON file\n",
        "json_file_path = '/content/drive/MyDrive/output_cascade/metrics.json'\n",
        "\n",
        "# Read data from JSON file\n",
        "json_data = []\n",
        "with open(json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        json_data.append(json.loads(line))\n",
        "\n",
        "# Extracting data\n",
        "iterations = [d[\"iteration\"] for d in json_data]\n",
        "total_losses = [d[\"total_loss\"] for d in json_data]\n",
        "loss_cls = [d[\"loss_cls_stage0\"] for d in json_data]\n",
        "loss_box_reg = [d[\"loss_box_reg_stage0\"] for d in json_data]\n",
        "loss_mask = [d[\"loss_mask\"] for d in json_data]\n",
        "accuracies = [d[\"mask_rcnn/accuracy\"] for d in json_data]\n",
        "false_negatives = [d[\"mask_rcnn/false_negative\"] for d in json_data]\n",
        "false_positives = [d[\"mask_rcnn/false_positive\"] for d in json_data]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Total Loss\n",
        "plt.subplot(3, 2, 1)\n",
        "plt.plot(iterations, total_losses, marker='o')\n",
        "plt.title('Total Loss over Iterations')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Total Loss')\n",
        "\n",
        "# Loss - Classification\n",
        "plt.subplot(3, 2, 2)\n",
        "plt.plot(iterations, loss_cls, marker='o', color='r')\n",
        "plt.title('Loss - Classification Stage 0 over Iterations')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss - Classification')\n",
        "\n",
        "# Loss - Box Regression\n",
        "plt.subplot(3, 2, 3)\n",
        "plt.plot(iterations, loss_box_reg, marker='o', color='g')\n",
        "plt.title('Loss - Box Regression Stage 0 over Iterations')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss - Box Regression')\n",
        "\n",
        "# Loss - Mask\n",
        "plt.subplot(3, 2, 4)\n",
        "plt.plot(iterations, loss_mask, marker='o', color='b')\n",
        "plt.title('Loss - Mask over Iterations')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss - Mask')\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(3, 2, 5)\n",
        "plt.plot(iterations, accuracies, marker='o', color='c')\n",
        "plt.title('Mask R-CNN Accuracy over Iterations')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "# False Positives and False Negatives\n",
        "plt.subplot(3, 2, 6)\n",
        "plt.plot(iterations, false_negatives, marker='o', color='m', label='False Negatives')\n",
        "plt.plot(iterations, false_positives, marker='o', color='y', label='False Positives')\n",
        "plt.title('False Positives and Negatives over Iterations')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lStMj_Vk3nKD"
      },
      "outputs": [],
      "source": [
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "shJUw70n3v8p",
        "outputId": "96cda4d3-81cf-492d-a8cf-9d0a43bd4ee0"
      },
      "outputs": [],
      "source": [
        "# Initialize the configuration\n",
        "cfg = get_cfg()\n",
        "\n",
        "# Load the base configuration from model zoo\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "\n",
        "# Set the path to the trained model weights\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/output_cascade/model_0003499.pth\"\n",
        "\n",
        "# Set the number of classes\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6  # Update this based on your dataset\n",
        "\n",
        "# Set the testing threshold for this model\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "\n",
        "# Specify the test dataset\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVdZ0sQp4QUN",
        "outputId": "eac43f1e-3bd5-4b44-b798-faeb5c38c9ab"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultPredictor\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3E9uvgKA4VpV",
        "outputId": "3f52f46f-5eda-4201-e9ed-955e15785f4a"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from google.colab.patches import cv2_imshow\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "# Name of the validation dataset\n",
        "dataset_name = \"my_dataset_val\"\n",
        "\n",
        "# Load the dataset\n",
        "dataset_dicts = DatasetCatalog.get(dataset_name)\n",
        "\n",
        "# Retrieve metadata\n",
        "dataset_metadata = MetadataCatalog.get(dataset_name)\n",
        "\n",
        "# Using the predictor to make predictions\n",
        "for d in random.sample(dataset_dicts, 7):\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=dataset_metadata,\n",
        "                   scale=0.5,\n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RcEolMO4Xt4",
        "outputId": "24a263d4-ba29-45e3-9f9b-3a8171ea99ff"
      },
      "outputs": [],
      "source": [
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "# Create a COCOEvaluator instance for your test dataset\n",
        "evaluator = COCOEvaluator(\"my_dataset_val\", cfg, False, output_dir=\"/content/drive/MyDrive/output1/evaluation\")\n",
        "\n",
        "# Build the test data loader\n",
        "test_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
        "\n",
        "# Run the model on the test data and get the evaluation metrics\n",
        "inference_on_dataset(predictor.model, test_loader, evaluator)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10 (pytorch)",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

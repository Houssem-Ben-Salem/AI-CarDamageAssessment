{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def is_coco_format(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Check if the main keys are present\n",
    "        if not all(key in data for key in [\"images\", \"annotations\", \"categories\"]):\n",
    "            return False\n",
    "\n",
    "        # Check if 'images' has the required keys\n",
    "        for image in data[\"images\"]:\n",
    "            if not all(key in image for key in [\"height\", \"width\", \"id\", \"file_name\"]):\n",
    "                return False\n",
    "\n",
    "        # Check if 'annotations' has the required keys\n",
    "        for annotation in data[\"annotations\"]:\n",
    "            if not all(key in annotation for key in [\"iscrowd\", \"image_id\", \"bbox\", \"category_id\", \"id\", \"area\"]):\n",
    "                return False\n",
    "\n",
    "        # Check if 'categories' has the required keys\n",
    "        for category in data[\"categories\"]:\n",
    "            if not all(key in category for key in [\"id\", \"name\"]):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/hous/Desktop/LLAVA/CarDD_release/CarDD_COCO/annotations/instances_train2017.json'\n",
    "result = is_coco_format(file_path)\n",
    "print(f\"Is COCO Format: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, \"/home/hous/Desktop/LLAVA/CarDD_release/CarDD_COCO/annotations/instances_train2017.json\", \"/home/hous/Desktop/LLAVA/CarDD_release/CarDD_COCO/train2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"my_dataset_val\", {}, \"/home/hous/Desktop/LLAVA/CarDD_release/CarDD_COCO/annotations/instances_val2017.json\", \"/home/hous/Desktop/LLAVA/CarDD_release/CarDD_COCO/val2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog\n",
    "\n",
    "def is_dataset_registered(name):\n",
    "    return name in DatasetCatalog.list()\n",
    "\n",
    "dataset_name = \"my_dataset_train\"\n",
    "if is_dataset_registered(dataset_name):\n",
    "    print(f\"The dataset '{dataset_name}' is registered.\")\n",
    "else:\n",
    "    print(f\"The dataset '{dataset_name}' is not registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset and retrieve metadata\n",
    "dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "dataset_metadata = MetadataCatalog.get(dataset_name)\n",
    "\n",
    "# Pick a random sample from the dataset\n",
    "sample = random.choice(dataset_dicts)\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(sample[\"file_name\"])\n",
    "\n",
    "# Create a Visualizer object\n",
    "visualizer = Visualizer(img[:, :, ::-1], metadata=dataset_metadata)\n",
    "\n",
    "# Visualize the annotations\n",
    "vis_output = visualizer.draw_dataset_dict(sample)\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "plt.imshow(vis_output.get_image()[:, :, ::-1])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetMapper, build_detection_train_loader\n",
    "from detectron2.data import transforms as T\n",
    "import copy\n",
    "import torch\n",
    "from detectron2.data import detection_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "\n",
    "    transform_list = [\n",
    "        T.RandomRotation(angle=[90, 180, 270]),  # Simple rotation\n",
    "        T.RandomContrast(0.8, 1.2),             # Random contrast\n",
    "        T.RandomBrightness(0.8, 1.2),           # Random brightness\n",
    "    ]\n",
    "\n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train_loader(cfg):\n",
    "    return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return custom_train_loader(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 8\n",
    "\n",
    "# Configure the model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = batch_size\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # Starting learning rate\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "cfg.SOLVER.MAX_ITER = 5000\n",
    "cfg.SOLVER.STEPS = (3000, 4000)  # Points to decrease the learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7\n",
    "\n",
    "# Learning rate scheduler configuration\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
    "cfg.SOLVER.GAMMA = 0.1  # Learning rate reduction factor\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "cfg.SOLVER.WEIGHT_DECAY = 0.001  # Regularization - weight decay\n",
    "\n",
    "# Set up output directory\n",
    "output_dir = \"/home/hous/Desktop/LLAVA/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cfg.OUTPUT_DIR = output_dir\n",
    "\n",
    "# Initialize the trainer and start training\n",
    "trainer = CustomTrainer(cfg)\n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
